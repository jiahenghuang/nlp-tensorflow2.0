- [x] seq2seq attention model

## preprocess with short text

![short train](https://github.com/shibing624/pycorrector/blob/master/pycorrector/data/git_image/short_train.png)


### result
![short correct result](https://github.com/shibing624/pycorrector/blob/master/pycorrector/data/git_image/short_result.png)

## preprocess with long text
### train data

![long train](https://github.com/shibing624/pycorrector/blob/master/pycorrector/data/git_image/long_train.png)

### result

![long correct result](https://github.com/shibing624/pycorrector/blob/master/pycorrector/data/git_image/long_text.png)

